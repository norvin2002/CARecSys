bank_convert <- data.frame(tempdata1, tempdata2, tempdata3, tempdata4, tempdata5, subset(bank, select=c(age, duration, consumer_price, account)))
bank_convert$age <- scale(bank_convert$age)
bank_convert$duration  <- scale(bank_convert$duration)
bank_convert$consumer_price  <- scale(bank_convert$consumer_price)
# save converted data for reference
#write.csv(bank_convert, "converted.csv")
table(bank_convert$account)
bank_convert$account <- as.integer(bank_convert$account=="yes")
table(bank_convert$account)
set.seed(123) # set the random seed to reproduce the results
TrainingDataIndex <- sample(1:nrow(bank_convert),round(0.70*nrow(bank_convert)))
train <- bank_convert[TrainingDataIndex,]
test <- bank_convert[-TrainingDataIndex,]
nrow(train)
#colnames(train)
nrow(test)
param_nodes_hidden_layer <- c(5,3,1) # No. of nodes at each hidden layer
param_max_iteration <- 1e5 # No. of iterations in training
param_learning_rate <- 0.1 # the learning rate during back propagation
# combine the attributes name for the convenience.
names <- colnames(bank_convert)
f <- as.formula(paste("account ~", paste(names[!names %in% "account"], collapse = " + ")))
tic("Neural network training")
nnmodel <- neuralnet(f, data = bank_convert, hidden=param_nodes_hidden_layer, stepmax=param_max_iteration, learningrate = param_learning_rate, linear.output=FALSE) #linear.output=FALSE means this is classification problem, as required by neuralnet package
toc()
plot(nnmodel)
print("NN model training is finished")
mypredict <- compute(nnmodel, test[,-1])$net.result
mypredict <- sapply(mypredict, round, digits=0)
results = data.frame(actual = test$account, prediction = mypredict)
table(results)
?predict
knitr::opts_chunk$set(echo = TRUE)
setwd('C:/Users/nchandra/OneDrive - National University of Singapore/PredictiveAnalytics/CA/data/')
set.seed(123)
pacman::p_load(tidyverse, caret, corrplot, caTools,knitr,car, ROCR,IRdisplay, e1071, earth, ROSE, smotefamily, rpart, rpart.plot, randomForest, pROC, DMwR)
loan <- read.csv('C:/Users/nchandra/OneDrive - National University of Singapore/PredictiveAnalytics/CA/data/loans.csv')
head(loan)
str(loan)
colname = c('creditpolicy', 'targetloanstatus')
loan[,colname] <- lapply(loan[,colname], as.factor)
ggplot(loan, aes(x = purpose, fill = targetloanstatus)) + geom_bar(position = 'fill') + theme(axis.text.x = element_text(angle=60, hjust=1))
ggplot(loan, aes(x = loanamnt, fill = targetloanstatus)) + geom_histogram()
loan %>%
group_by(targetloanstatus) %>%
summarise(percentage = n() /nrow(loan)) %>%
ggplot(aes(x = targetloanstatus, y = percentage, fill = targetloanstatus)) + geom_bar(stat = 'identity') +
geom_text(aes(label = round(percentage,2)),vjust = 2, color = 'White')
print(paste('Proportion of missing data from whole: ',as.character(nrow(loan[rowSums(is.na(loan)) > 0,])/nrow(loan) * 100),'%'))
loan1 <- loan[complete.cases(loan),]
# check if there is still any NA
nrow(loan1[rowSums(is.na(loan1)) > 0, ])
nrow(loan1[loan1['emplength'] == 'n/a',])
loan1 <- loan1 %>%
filter(emplength != 'n/a') %>%
droplevels()
loan1$total_loan <- loan1$installment * parse_number(as.character(loan1$term))
head(loan1)
loan1 %>%
filter(targetloanstatus == 1)%>%
ggplot(aes(x= 1, y = total_loan))+geom_boxplot()
loan1 %>%
filter(targetloanstatus != 1)%>%
ggplot(aes(x= 1, y = total_loan))+geom_boxplot()
med_FN <- median(loan1$total_loan[loan1$targetloanstatus == 1])
print(paste('Median total_loan:', med_FN))
med_FP <- median(loan1$total_loan[loan1$targetloanstatus == 0])
print(paste('Median total_loan:', med_FP))
splitData = sample.split(loan1$targetloanstatus, SplitRatio = 0.7)
#train set
train_set <- loan1[splitData,]
#nrow(train_set) / nrow(loan1)
#test set
test_set <- loan1[!splitData,]
#nrow(test_set) / nrow(loan1)
train_set_ROSE <- ovun.sample(targetloanstatus ~ ., method = 'over', data = train_set, N = 49240, seed = 1)$data
table(train_set_ROSE$targetloanstatus)
#create train & validation out of the total train_set
splitDataTrain = sample.split(train_set_ROSE$targetloanstatus, SplitRatio = 0.8)
#train ROSE
train_set_ROSEt <- train_set_ROSE[splitDataTrain,]
#validation ROSE
validation_set_ROSE <- train_set_ROSE[!splitDataTrain,]
train_set_smote <- SMOTE(targetloanstatus~., train_set, perc.over=100)
#create train & validation out of the train_set_smote
splitDataTrainS <- sample.split(train_set_smote$targetloanstatus, SplitRatio = 0.8)
#actual train SMOTE
train_set_smotet <- train_set_smote[splitDataTrainS, ]
#actual validation SMOTE
validation_set_smotet <- train_set_smote[!splitDataTrainS,]
lr1 <- glm(targetloanstatus ~ loanamnt + term + installment + emplength + homeownership + annualinc + verificationstatus + purpose + dti + delinq2yrs + inqlast6mths + openacc + revolbal + totalacc + intrate + revolutil + total_loan, data = train_set, family = binomial )
summary(lr1)
vif(lr1)
lr2 <- glm(targetloanstatus ~ term + emplength + homeownership + annualinc + purpose + inqlast6mths + revolbal + totalacc + intrate + revolutil, data = train_set, family = binomial )
summary(lr2)
lr3 <- glm(targetloanstatus ~ term + emplength + homeownership + annualinc + purpose + inqlast6mths + revolbal + intrate + revolutil, data = train_set, family = binomial )
summary(lr3)
vif(lr3)
testPredictlr3 = predict(lr3, newdata = test_set, type = 'response')
p_class_testlr3 <- ifelse(testPredictlr3 > 0.5, 1, 0)
matrix_testlr3 <- table(test_set$targetloanstatus, p_class_testlr3)
print(paste('Matrix lr3: ', matrix_testlr3))
accuracy_testlr3 <- sum(diag(matrix_testlr3))/sum(matrix_testlr3)
print(paste('Accuracy lr3: ', accuracy_testlr3))
#roc_testlr3 <- roc(test_set$targetloanstatus, testPredict_lr3)
precision_testlr3 <- matrix_testlr3[2,2] / sum(matrix_testlr3[,2])
specificity_testlr3 <- matrix_testlr3[1,1] / sum(matrix_testlr3[1,])
recall_testlr3 <- matrix_testlr3[2,2] /sum(matrix_testlr3[2,])
print(paste('Recall lr3: ', recall_testlr3))
roc_testlr3 <- roc(test_set$targetloanstatus, p_class_testlr3)
test_target <- ifelse(test_set$targetloanstatus == '0', 0, 1)
max(mean(test_target), 1- mean(test_target))
lr4 <- glm(targetloanstatus ~ term + emplength + homeownership + annualinc + purpose +
inqlast6mths + revolbal + intrate + revolutil,
data = train_set_ROSEt, family = binomial )
summary(lr4)
vif(lr4)
testPredict_lr4 = predict(lr4, newdata = test_set, type = 'response')
p_class_testlr4 <- ifelse(testPredict_lr4 > 0.5, 1, 0) # as the train_set is balanced, we use 0.5 as treshold
p_class_factor_testlr4 <- factor(ifelse(testPredict_lr4 > 0.5, '1', '0'))
matrix_testlr4 <- table(test_set$targetloanstatus, p_class_testlr4)
matrix_testlr4
precision_testlr4 <- matrix_testlr4[2,2] / sum(matrix_testlr4[,2])
specificity_testlr4 <- matrix_testlr4[1,1] / sum(matrix_testlr4[1,])
accuracy_testlr4 <- sum(diag(matrix_testlr4))/sum(matrix_testlr4)
print(paste('Accuracy lr4:', accuracy_testlr4))
roc_testlr4 <- roc(test_set$targetloanstatus, p_class_testlr4)
recall_testlr4 <- matrix_testlr4[2,2] / sum(matrix_testlr4[2,])
print(paste('Recall lr4: ', recall_testlr4))
lr5 <- glm(targetloanstatus ~ term + emplength + homeownership + annualinc +
purpose + inqlast6mths + revolbal + intrate + revolutil,
data = train_set_smotet, family = binomial )
summary(lr5)
vif(lr5)
testPredict_lr5 <- predict(lr5, newdata = test_set, type = 'response')
p_class_testlr5 <- ifelse(testPredict_lr5 > 0.5, 1, 0)
matrix_testlr5 <- table(test_set$targetloanstatus, p_class_testlr5)
matrix_testlr5
precision_testlr5 <- matrix_testlr5[2,2] / sum(matrix_testlr5[,2])
specificity_testlr5 <- matrix_testlr5[1,1] / sum(matrix_testlr5[1,])
roc_testlr5 <- roc(test_set$targetloanstatus, testPredict_lr5)
recall_testlr5 <- matrix_testlr5[2,2]/sum(matrix_testlr5[2,])
print(paste('Recall lr5: ', recall_testlr5))
accuracy_testlr5 <- sum(diag(matrix_testlr5))/sum(matrix_testlr5)
print(paste('Accuracy lr5:', accuracy_testlr5))
tree1 <- rpart(targetloanstatus ~ loanamnt + term + installment + emplength+ homeownership + annualinc +
verificationstatus + purpose + dti + delinq2yrs + inqlast6mths + openacc +
revolbal + totalacc + intrate + revolutil, data = train_set_ROSEt, method = 'class',
minsplit = 5,
parms = list(split = "information"),
control=rpart.control(maxdepth=10,
usesurrogate=0,
maxsurrogate=0))
varImp(tree1)
tree3 <- rpart(targetloanstatus ~ term + annualinc +
purpose + inqlast6mths +
intrate + revolutil, data = train_set_ROSEt, method = 'class',
minsplit = 5,
parms = list(split = "information"),
control=rpart.control(maxdepth=10,
usesurrogate=0,
maxsurrogate=0))
varImp(tree3)
testPredict_tree3 <- predict(tree3, test_set, type = 'prob')
p_class_testtree3 <- ifelse(testPredict_tree3[,2] > 0.5, 1, 0)
matrix_testtree3 <- table(test_set$targetloanstatus, p_class_testtree3)
matrix_testtree3
accuracy_testtree3 <- sum(diag(matrix_testtree3))/sum(matrix_testtree3)
print(paste('Accuracy tree3: ',accuracy_testtree3))
precision_testtree3 <- matrix_testtree3[2,2] / sum(matrix_testtree3[,2])
specificity_testtree3 <- matrix_testtree3[1,1] / sum(matrix_testtree3[1,])
recall_testtree3 <- matrix_testtree3[2,2] / sum(matrix_testtree3[2,])
print(paste('Recall tree3', recall_testtree3))
roc_testtree3 <- roc(test_set$targetloanstatus, as.numeric(p_class_testtree3))
tree4 <-rpart(targetloanstatus ~ term + annualinc +
purpose + inqlast6mths +
intrate + revolutil, data = train_set_smotet, method = 'class',
minsplit = 5,
parms = list(split = "information"),
control=rpart.control(maxdepth=10,
usesurrogate=0,
maxsurrogate=0))
varImp(tree4)
testPredict_tree4 <- predict(tree4, test_set, type = 'prob')
p_class_testtree4 <- ifelse(testPredict_tree4[,2] > 0.5, 1, 0)
matrix_testtree4 <- table(test_set$targetloanstatus, p_class_testtree4)
matrix_testtree4
precision_testtree4 <- matrix_testtree4[2,2] / sum(matrix_testtree4[,2])
specificity_testtree4 <- matrix_testtree4[1,1] / sum(matrix_testtree4[1,])
accuracy_testtree4 <- sum(diag(matrix_testtree4))/sum(matrix_testtree4)
print(paste('Accuracy tree4:',accuracy_testtree4))
recall_testtree4 <- matrix_testtree4[2,2]/sum(matrix_testtree4[2,])
print(paste('Recall tree4:',recall_testtree4))
roc_testtree4 <- roc(test_set$targetloanstatus, as.numeric(p_class_testtree4))
rf1 <- randomForest(targetloanstatus ~ loanamnt + term + installment + emplength + homeownership + annualinc +
verificationstatus + purpose + dti + delinq2yrs + inqlast6mths + openacc +
revolbal + totalacc + intrate + revolutil,
data = train_set_ROSEt,
importance = TRUE,
ntree = 200)
varImp(rf1)
testPredict_rf1 <- predict(rf1, test_set, type = 'prob')
p_class_testrf1 <- ifelse(testPredict_rf1[,2] > 0.5, 1, 0)
matrix_testrf1 <- table(test_set$targetloanstatus, p_class_testrf1)
matrix_testrf1
recall_testrf1 <- matrix_testrf1[2,2] /sum(matrix_testrf1[2,])
print(paste('Recall rf1:', recall_testrf1))
precision_testrf1 <- matrix_testrf1[2,2] / sum(matrix_testrf1[,2])
specificity_testrf1 <- matrix_testrf1[1,1] / sum(matrix_testrf1[1,])
roc_testrf1 <- roc(response = test_set$targetloanstatus, predictor = as.numeric(p_class_testrf1))
accuracy_testrf1 <- sum(diag(matrix_testrf1))/sum(matrix_testrf1)
accuracy_testrf1
rf2 <- randomForest(targetloanstatus ~ loanamnt + term + installment + emplength + homeownership + annualinc +
verificationstatus + purpose + dti + delinq2yrs + inqlast6mths + openacc +
revolbal + totalacc + intrate + revolutil,
data = train_set_smotet,
importance = TRUE,
ntree = 200)
testPredict_rf2 <- predict(rf2, test_set, type = 'prob')
p_class_testrf2 <- ifelse(testPredict_rf2[,2] > 0.5, 1, 0)
matrix_testrf2= table(test_set$targetloanstatus, p_class_testrf2)
matrix_testrf2
precision_testrf2 <- matrix_testrf2[2,2] / sum(matrix_testrf2[,2])
specificity_testrf2 <- matrix_testrf2[1,1] / sum(matrix_testrf2[1,])
recall_testrf2 <- matrix_testrf2[2,2]/sum(matrix_testrf2[2,])
print(paste('Recall rf2:', recall_testrf2))
accuracy_testrf2 <- sum(diag(matrix_testrf2))/sum(matrix_testrf2)
print(paste('Accuracy rf2:', accuracy_testrf2))
roc_testrf2 <- roc(test_set$targetloanstatus, as.numeric(p_class_testrf2))
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
lrcv2 <- train(targetloanstatus ~ term + emplength + homeownership + annualinc +
purpose + inqlast6mths + revolbal + intrate + revolutil ,
data = train_set_ROSE,
trControl = train_control,
method = "glm",
family=binomial())
# print cv scores
summary(lrcv2)
lrcv2$results
testPredict_lrcv2 <- predict(lrcv2, test_set, 'prob')
p_class_testlrcv2 <- ifelse(testPredict_lrcv2[,2] > 0.5, 1, 0)
matrix_testPredictlrcv2 <- table(test_set$targetloanstatus, p_class_testlrcv2)
matrix_testPredictlrcv2
precision_testlrcv2 <- matrix_testPredictlrcv2[2,2] / sum(matrix_testPredictlrcv2[,2])
specificity_testlrcv2 <- matrix_testPredictlrcv2[1,1] / sum(matrix_testPredictlrcv2[1,])
accuracy_testlrcv2 <- sum(diag(matrix_testPredictlrcv2))/sum(matrix_testPredictlrcv2)
print(paste('Accuracy lrcv2:', accuracy_testlrcv2))
recall_testlrcv2 <- matrix_testPredictlrcv2[2,2] / sum(matrix_testPredictlrcv2[2,])
print(paste('Recall lrcv2:', recall_testlrcv2))
roc_lrcv2 <- roc(test_set$targetloanstatus, as.numeric(p_class_testlrcv2))
# train the model on training set
lrcv3 <- train(targetloanstatus ~ term + emplength + homeownership + annualinc +
purpose + inqlast6mths + revolbal + intrate + revolutil ,
data = train_set_smote,
trControl = train_control,
method = "glm",
family=binomial())
# print cv scores
summary(lrcv3)
lrcv3$results
testPredict_lrcv3 <- predict(lrcv3, newdata = test_set, type = 'prob')
p_class_testlrcv3 <- as.numeric(ifelse(testPredict_lrcv3['1'] > 0.5, 1, 0))
matrix_testPredictlrcv3 <- table(test_set$targetloanstatus, p_class_testlrcv3)
matrix_testPredictlrcv3
precision_testlrcv3 <- matrix_testPredictlrcv3[2,2] / sum(matrix_testPredictlrcv3[,2])
specificity_testlrcv3 <- matrix_testPredictlrcv3[1,1] / sum(matrix_testPredictlrcv3[1,])
accuracy_testlrcv3 <- sum(diag(matrix_testPredictlrcv3))/sum(matrix_testPredictlrcv3)
print(paste('Accuracy lrcv3:', accuracy_testlrcv3))
recall_testlrcv3 <- matrix_testPredictlrcv3[2,2] / sum(matrix_testPredictlrcv3[2,])
print(paste('Recall lrcv3:', recall_testlrcv3))
roc_lrcv3 <- roc(test_set$targetloanstatus, as.numeric(p_class_testlrcv3))
plot(roc_testlr3, col = 'grey')
plot(roc_testlr4, add = TRUE, col = 'purple')
plot(roc_testlr5, add = TRUE, col = 'red')
plot(roc_testtree3, add = TRUE, col = 'green')
plot(roc_testtree4, add = TRUE, col = 'blue')
plot(roc_testrf1, add = TRUE, col = 'pink')
plot(roc_testrf2, add = TRUE, col = 'orange')
plot(roc_lrcv2, add = TRUE)
plot(roc_lrcv3, add = TRUE)
legend(x = "bottomright",
legend = c("LogisticReg","LogisticReg_ROSE", "LogisticReg_SMOTE", "DTree_ROSE", "DTree_SMOTE", 'RandomForest_ROSE', 'RandomForest_SMOTE', 'LogisticRegCV_ROSE', 'LogisticRegCV_SMOTE'), fill = 1:9)
performance <- data.frame('model' = c('Logistic Regression','Logistic Regression ROSE', 'Logistic Regression SMOTE', 'Tree ROSE', 'Tree SMOTE', 'Forest ROSE', 'Forest SMOTE', 'Logistic Regression ROSE CV', 'Logistic Regression SMOTE CV'),
'recall' = c(recall_testlr3, recall_testlr4, recall_testlr5, recall_testtree3, recall_testtree4, recall_testrf1, recall_testrf2, recall_testlrcv2, recall_testlrcv3),
'accuracy' = c(accuracy_testlr3, accuracy_testlr4, accuracy_testlr5, accuracy_testtree3, accuracy_testtree4, accuracy_testrf1, accuracy_testrf2, accuracy_testlrcv2, accuracy_testlrcv3))
print(performance)
test_set_result <- cbind(test_set[c('id','total_loan','targetloanstatus')],
'targetloanstatus_lr' = p_class_testlr3, 'targetloanstatus_lr_rose' = p_class_testlr4, 'targetloanstatus_lr_smote' = p_class_testlr5,
'targetloanstatus_tree_rose' = p_class_testtree3, 'targetloanstatus_tree_smote' = p_class_testtree4,
'targetloanstatus_rf_rose' = p_class_testrf1, 'targetloanstatus_rf_smote'= p_class_testrf2,
'targetloanstatus_lrcv_rose' = p_class_testlrcv2, 'targetloanstatus_lrcv_smote' = p_class_testlrcv3)
#(test_set_result)
FP_lr <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr == 1), 'total_loan'])
FN_lr <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr == 0), 'total_loan'])
FP_lr_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr_rose == 1), 'total_loan'])
FN_lr_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr_rose == 0), 'total_loan'])
FP_lr_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr_smote == 1), 'total_loan'])
FN_lr_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr_smote == 0), 'total_loan'])
FP_lrcv_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lrcv_smote == 1), 'total_loan'])
FN_lrcv_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lrcv_smote == 0), 'total_loan'])
FP_lrcv_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lrcv_rose == 1), 'total_loan'])
FN_lrcv_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lrcv_rose == 0), 'total_loan'])
FP_tree_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_tree_rose == 1), 'total_loan'])
FN_tree_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_tree_rose == 0), 'total_loan'])
FP_tree_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_tree_smote == 1), 'total_loan'])
FN_tree_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_tree_smote == 0), 'total_loan'])
FP_rf_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_rf_rose == 1), 'total_loan'])
FN_rf_rose <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_rf_rose == 0), 'total_loan'])
FP_rf_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_rf_smote == 1), 'total_loan'])
FN_rf_smote <- sum(test_set_result[which(test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_rf_smote == 0), 'total_loan'])
no_mod <- sum(test_set_result[which(test_set_result$targetloanstatus == 1), 'total_loan'])
#print(paste('Cost of default without any model application: ', format(no_mod, big.mark=','), sep = ""))
cost <- data.frame('model' = c('Logistic Regression','Logistic Regression ROSE', 'Logistic Regression SMOTE', 'Tree ROSE', 'Tree SMOTE', 'Forest ROSE', 'Forest SMOTE', 'Logistic Regression ROSE CV', 'Logistic Regression SMOTE CV'),
'False Positive Cost' = c(FP_lr, FP_lr_rose, FP_lr_smote, FP_tree_rose, FP_tree_smote, FP_rf_rose, FP_rf_smote, FP_lrcv_rose, FP_lrcv_smote),
'False Negative Cost' = c(FN_lr, FN_lr_rose, FN_lr_smote, FN_tree_rose, FN_tree_smote, FN_rf_rose, FN_rf_smote, FN_lrcv_rose, FN_lrcv_smote)
)
cost <- cbind(cost, totalcost = rowSums(cost[,-1]))
cost.perf <- cbind(performance, cost[-1])
cost.perf$costdiffwithnomod <- cost.perf$totalcost - no_mod
#print(cost.perf[order(cost.perf$totalcost),])
knitr::kable(cost.perf[order(cost.perf$totalcost),])
FP_lr_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr == 1))
FN_lr_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr == 0))
FP_lr_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr_rose == 1))
FN_lr_rose_count<- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr_rose == 0))
FP_lr_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lr_smote == 1))
FN_lr_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lr_smote == 0))
FP_lrcv_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lrcv_rose == 1))
FN_lrcv_rose_count<- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lrcv_rose == 0))
FP_lrcv_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_lrcv_smote == 1))
FN_lrcv_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_lrcv_smote == 0))
FP_tree_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_tree_rose == 1))
FN_tree_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_tree_rose == 0))
FP_tree_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_tree_smote == 1))
FN_tree_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_tree_smote == 0))
FP_rf_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_rf_rose == 1))
FN_rf_rose_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_rf_rose == 0))
FP_rf_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 0 & test_set_result$targetloanstatus_rf_smote == 1))
FN_rf_smote_count <- nrow(subset(test_set_result, test_set_result$targetloanstatus == 1 & test_set_result$targetloanstatus_rf_smote == 0))
cost2 <- data.frame('model' = c('Logistic Regression','Logistic Regression ROSE', 'Logistic Regression SMOTE',
'Tree ROSE', 'Tree SMOTE', 'Forest ROSE', 'Forest SMOTE', 'Logistic Regression CV ROSE',
'Logistic Regression CV SMOTE'),
'False Positive Count' = c(FP_lr_count, FP_lr_rose_count, FP_lr_smote_count,
FP_tree_rose_count, FP_tree_smote_count, FP_rf_rose_count,
FP_rf_smote_count, FP_lrcv_rose_count, FP_lrcv_smote_count),
'False Negative Count' = c(FN_lr_count, FN_lr_rose_count, FN_lr_smote_count, FN_tree_rose_count,
FN_tree_smote_count, FN_rf_rose_count, FN_rf_smote_count, FN_lrcv_rose_count,
FN_lrcv_smote_count)
)
cost.perf2 <- cbind(cost2, totalcost = cost2$False.Positive.Count * med_FP + cost2$False.Negative.Count * med_FN)
cost.perf2$costdiffwithnomod <- cost.perf2$totalcost - no_mod
knitr::kable(cost.perf2[order(cost.perf2$costdiffwithnomod),])
ori_FP = nrow(test_set[test_set$targetloanstatus == 0 & test_set$creditpolicy == 0,])/ nrow(test_set)
ori_FP
ori_FN <- nrow(test_set[test_set$targetloanstatus == 1 & test_set$creditpolicy == 1,]) / nrow(test_set)
ori_FN
FP_lr <- FP_lr_count / nrow(test_set)
FN_lr <- FN_lr_count / nrow(test_set)
FP_lr_rose <-FP_lr_rose_count / nrow(test_set)
FN_lr_rose <- FN_lr_rose_count / nrow(test_set)
FP_lr_smote <- FP_lr_smote_count / nrow(test_set)
FN_lr_smote <- FN_lr_smote_count / nrow(test_set)
FP_tree_rose <- FP_tree_rose_count /nrow(test_set)
FN_tree_rose <- FN_tree_rose_count /nrow(test_set)
FP_tree_smote <- FP_tree_smote_count / nrow(test_set)
FN_tree_smote <- FN_tree_smote_count / nrow(test_set)
FP_rf_rose <- FP_rf_rose_count / nrow(test_set)
FN_rf_rose <- FN_rf_rose_count / nrow(test_set)
FP_rf_smote <- FP_rf_smote_count / nrow(test_set)
FN_rf_smote <- FN_rf_smote_count / nrow(test_set)
comp <- data.frame('measure' = c('FP', 'FN'),
'without model' = c(ori_FP, ori_FN),
'base lr' = c(FP_lr, FN_lr),
'lr ROSE' = c(FP_lr_rose, FN_lr_rose),
'lr SMOTE' = c(FP_lr_smote, FN_lr_smote),
'tree ROSE' = c(FP_tree_rose, FN_tree_rose),
'tree SMOTE' = c(FP_tree_smote, FN_tree_smote),
'rf ROSE' = c(FP_rf_rose, FN_rf_rose),
'rf SMOTE' = c(FP_rf_smote, FN_rf_smote))
comp
comp1 <- subset(transform(comp, measure = c('FP', 'FN'),
diffbase = base.lr -without.model ,
difflr.rose = lr.ROSE - without.model ,
difflr.smote = lr.SMOTE - without.model,
difftree.rose = tree.ROSE - without.model,
difftree.smote = tree.SMOTE - without.model,
diffrf.rose = rf.ROSE - without.model,
diffrf.smote = rf.SMOTE - without.model),
select = c('measure','diffbase', 'difflr.rose', 'difflr.smote', 'difftree.rose',
'difftree.smote', 'diffrf.rose', 'diffrf.smote')
)
comp1 <- rbind(comp1[,-1], comp1[1,-1] * med_FP + comp1[2,-1] * med_FN)
comp1 <- cbind(measure = c('FP change', 'FN change', 'Expected Cost per Prediction'), comp1)
comp1 <- comp1 %>%
mutate_if(is.numeric, round, digits = 2)
print(comp1)
install.packages('rmarkdown')
install.packages('rmarkdown')
install.packages('knitr')
knitr::opts_chunk$set(echo = TRUE)
testPredictlr3 = predict(lr3, newdata = test_set, type = 'response')
perf = performance( testPredictlr3, "lift", "rpp" )
shiny::runApp('C:/Users/nchandra/OneDrive - National University of Singapore/Shiny')
rsconnect::deployApp()
runApp('C:/Users/nchandra/OneDrive - National University of Singapore/Shiny')
deployApp()
shiny::deployApp()
install.packages("RSQLite")
# ! Set your working directory
#setwd("C:/Users/zamsg/Documents/GitHub/CARecSys/Data")
setwd('C:/Users/nchandra/OneDrive - National University of Singapore/CARecSys/Data')
# Read in data
hotels <- read.csv("Booking.csv", stringsAsFactor=FALSE)
# Understand the data
names(hotels)
names(hotels)[1] <- "hotel_name"
length(unique(hotels$hotel_name)) # 24 hotels
length(unique(hotels$reviewer_country)) # 118 reviewer_country
# Data Preparation (intial)
hotels$review_date <- substring(hotels$review_date, 11)
hotels$review_date <- as.Date(strptime(hotels$review_date, format = "%d %B %Y"))
hotels$review_header <- substring(hotels$review_header, first = 4, last = nchar(hotels$review_header)-3)
hotels$stay <- as.Date(strptime((paste((substring(hotels$stay, 11)), "01")), format = "%B %Y %d"))
sapply(hotels, class)
# Data explorary
barplot(sort(table(hotels$hotel_name)), main ="Reviews for each Hotels", ylab = "No. of Reviews", las = 2)
hist(hotels$reviewer_rating, breaks = seq(0, 10, by = 1),
main = "Distribution of viewer Rating", xlab = "reviewer rating")
hotels %>%
group_by(hotel_name) %>%
summarise(overall_score = mean(overall_score)) %>%
ggplot(aes(x = reorder(as.factor(hotel_name), overall_score), y = overall_score)) + geom_bar(stat = 'identity') +
labs(x = "hotel_name", title = "Overall Score for Singapore Hotels in Little India") +
coord_flip()
hotels %>%
group_by(hotel_name) %>%
summarise(overall_score = mean(overall_score)) %>%
ggplot(aes(x = reorder(as.factor(hotel_name), overall_score), y = overall_score)) + geom_bar(stat = 'identity') +
labs(x = "hotel_name", title = "Overall Score for Singapore Hotels in Little India") +
coord_flip()
# Read in data
hotels <- read.csv("Booking.csv", stringsAsFactor=FALSE)
# Understand the data
names(hotels)
names(hotels)[1] <- "hotel_name"
length(unique(hotels$hotel_name)) # 24 hotels
length(unique(hotels$reviewer_country)) # 118 reviewer_country
# Data Preparation (intial)
hotels$review_date <- substring(hotels$review_date, 11)
hotels$review_date <- as.Date(strptime(hotels$review_date, format = "%d %B %Y"))
hotels$review_header <- substring(hotels$review_header, first = 4, last = nchar(hotels$review_header)-3)
hotels$stay <- as.Date(strptime((paste((substring(hotels$stay, 11)), "01")), format = "%B %Y %d"))
sapply(hotels, class)
# Data explorary
barplot(sort(table(hotels$hotel_name)), main ="Reviews for each Hotels", ylab = "No. of Reviews", las = 2)
hist(hotels$reviewer_rating, breaks = seq(0, 10, by = 1),
main = "Distribution of viewer Rating", xlab = "reviewer rating")
table(hotels$review_count) # positive skewed
hist(hotels$review_count, breaks = 20,
main = "No. of Review Counts of the Reviewers", xlab = "review counts") # majority reviewers have less than 10 reviews
hotels %>%
group_by(hotel_name) %>%
summarise(overall_score = mean(overall_score)) %>%
ggplot(aes(x = reorder(as.factor(hotel_name), overall_score), y = overall_score)) + geom_bar(stat = 'identity') +
labs(x = "hotel_name", title = "Overall Score for Singapore Hotels in Little India") +
coord_flip()
# library
library(dplyr)
library(ggplot2)
# ! Set your working directory
#setwd("C:/Users/zamsg/Documents/GitHub/CARecSys/Data")
setwd('C:/Users/nchandra/OneDrive - National University of Singapore/CARecSys/Data')
# Read in data
hotels <- read.csv("Booking.csv", stringsAsFactor=FALSE)
# Understand the data
names(hotels)
names(hotels)[1] <- "hotel_name"
length(unique(hotels$hotel_name)) # 24 hotels
length(unique(hotels$reviewer_country)) # 118 reviewer_country
# Data Preparation (intial)
hotels$review_date <- substring(hotels$review_date, 11)
hotels$review_date <- as.Date(strptime(hotels$review_date, format = "%d %B %Y"))
hotels$review_header <- substring(hotels$review_header, first = 4, last = nchar(hotels$review_header)-3)
hotels$stay <- as.Date(strptime((paste((substring(hotels$stay, 11)), "01")), format = "%B %Y %d"))
sapply(hotels, class)
# Data explorary
barplot(sort(table(hotels$hotel_name)), main ="Reviews for each Hotels", ylab = "No. of Reviews", las = 2)
hist(hotels$reviewer_rating, breaks = seq(0, 10, by = 1),
main = "Distribution of viewer Rating", xlab = "reviewer rating")
table(hotels$review_count) # positive skewed
hist(hotels$review_count, breaks = 20,
main = "No. of Review Counts of the Reviewers", xlab = "review counts") # majority reviewers have less than 10 reviews
hotels %>%
group_by(hotel_name) %>%
summarise(overall_score = mean(overall_score)) %>%
ggplot(aes(x = reorder(as.factor(hotel_name), overall_score), y = overall_score)) + geom_bar(stat = 'identity') +
labs(x = "hotel_name", title = "Overall Score for Singapore Hotels in Little India") +
coord_flip()
# Understand the data
names(hotels)
names(hotels)[1] <- "hotel_name"
length(unique(hotels$hotel_name)) # 24 hotels
length(unique(hotels$reviewer_country)) # 118 reviewer_country
# Data Preparation (intial)
hotels$review_date <- substring(hotels$review_date, 11)
# Data Preparation (intial)
hotels$review_date <- substring(hotels$review_date, 11)
head(hotels)
head(hotels)
hotels[1,]
